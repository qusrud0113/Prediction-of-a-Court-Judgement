{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATRUE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United States       154\n",
       "Illinois              9\n",
       "Maryland              8\n",
       "Florida               8\n",
       "New York              7\n",
       "                   ... \n",
       "David Carpenter       1\n",
       "Larry Gene Heath      1\n",
       "PGA TOUR, Inc.        1\n",
       "PPL Montana, LLC      1\n",
       "Markman               1\n",
       "Name: first_party, Length: 2110, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['first_party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "United States                        240\n",
       "California                            19\n",
       "United States of America              15\n",
       "Illinois                              13\n",
       "Federal Communications Commission     10\n",
       "                                    ... \n",
       "David Boren, Governor of Oklahoma      1\n",
       "Federal Bureau of Prisons et al.       1\n",
       "Town of Harrison                       1\n",
       "Charles Burr et al.                    1\n",
       "Westview Instruments, Inc.             1\n",
       "Name: second_party, Length: 1974, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['second_party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_frequency(df):\n",
    "    tf1 = (df['facts'][1:2]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
    "    tf1.columns = ['words','tf']\n",
    "    return tf1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       On June 27, 1962, Phil St. Amant, a candidate ...\n",
       "1       Ramon Nelson was riding his bike when he suffe...\n",
       "2       An Alabama state court convicted Billy Joe Mag...\n",
       "3       Victor Linkletter was convicted in state court...\n",
       "4       On April 24, 1953 in Selma, Alabama, an intrud...\n",
       "                              ...                        \n",
       "2473    Congress amended the Clean Air Act through the...\n",
       "2474    Alliance Bond Fund, Inc., an investment fund, ...\n",
       "2475    In 1992, the District Court sentenced Manuel D...\n",
       "2476    On March 8, 1996, Enrico St. Cyr, a lawful per...\n",
       "2477    Herbert Markman owns the patent to a system th...\n",
       "Name: facts, Length: 2478, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['facts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Owens’</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>distribution,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>potentially</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>crack</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>trial.\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             index   0\n",
       "0              the  12\n",
       "1                a   8\n",
       "2              was   8\n",
       "3              and   8\n",
       "4               of   7\n",
       "..             ...  ..\n",
       "117         Owens’   1\n",
       "118  distribution,   1\n",
       "119    potentially   1\n",
       "120          crack   1\n",
       "121       trial.\\n   1\n",
       "\n",
       "[122 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['facts'][1:2].apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       On June 27, 1962, Phil St. Amant, a candidate ...\n",
       "1       Ramon Nelson was riding his bike when he suffe...\n",
       "2       An Alabama state court convicted Billy Joe Mag...\n",
       "3       Victor Linkletter was convicted in state court...\n",
       "4       On April 24, 1953 in Selma, Alabama, an intrud...\n",
       "                              ...                        \n",
       "2473    Congress amended the Clean Air Act through the...\n",
       "2474    Alliance Bond Fund, Inc., an investment fund, ...\n",
       "2475    In 1992, the District Court sentenced Manuel D...\n",
       "2476    On March 8, 1996, Enrico St. Cyr, a lawful per...\n",
       "2477    Herbert Markman owns the patent to a system th...\n",
       "Name: facts, Length: 2478, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 출력 옵션 설정\n",
    "# pd.set_option(\"display.max_rows\", None)  # 모든 행 표시\n",
    "pd.set_option(\"display.max_columns\", None)  # 모든 열 표시\n",
    "pd.set_option(\"display.width\", None)  # 줄 바꿈 없이 전체 내용 표시\n",
    "data['facts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1]['facts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[0]['facts']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['first_party_winner'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "subset_0 = data[data[\"first_party_winner\"] == 0]\n",
    "subset_1 = data[data[\"first_party_winner\"] == 1]\n",
    "\n",
    "subset_1_downsampled = resample(subset_1,\n",
    "                                replace=False,\n",
    "                                n_samples=800,\n",
    "                                random_state=42)\n",
    "\n",
    "data = pd.concat([subset_0, subset_1_downsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    829\n",
       "1    800\n",
       "Name: first_party_winner, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['first_party_winner'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/chunbae/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/chunbae/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/chunbae/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers.tokenization_utils import TruncationStrategy\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def stem_text_func(text):\n",
    "    token_words=word_tokenize(text)\n",
    "    stem_sentence = []\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "# 불용어 리스트\n",
    "languages = [\n",
    "   'English'\n",
    "]\n",
    "my_stop_word_list = []\n",
    "for i in languages:\n",
    "    my_stop_word_list.append(get_stop_words(i.lower()))\n",
    "my_stop_word_list = sum(my_stop_word_list, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/nealrs/96342d8231b75cf4bb82\n",
    "contractions = {\n",
    "  \"ain't\": \"am not\",\n",
    "  \"aren't\": \"are not\",\n",
    "  \"can't\": \"cannot\",\n",
    "  \"can't've\": \"cannot have\",\n",
    "  \"'cause\": \"because\",\n",
    "  \"could've\": \"could have\",\n",
    "  \"couldn't\": \"could not\",\n",
    "  \"couldn't've\": \"could not have\",\n",
    "  \"didn't\": \"did not\",\n",
    "  \"doesn't\": \"does not\",\n",
    "  \"don't\": \"do not\",\n",
    "  \"hadn't\": \"had not\",\n",
    "  \"hadn't've\": \"had not have\",\n",
    "  \"hasn't\": \"has not\",\n",
    "  \"haven't\": \"have not\",\n",
    "  \"he'd\": \"he would\",\n",
    "  \"he'd've\": \"he would have\",\n",
    "  \"he'll\": \"he will\",\n",
    "  \"he'll've\": \"he will have\",\n",
    "  \"he's\": \"he is\",\n",
    "  \"how'd\": \"how did\",\n",
    "  \"how'd'y\": \"how do you\",\n",
    "  \"how'll\": \"how will\",\n",
    "  \"how's\": \"how is\",\n",
    "  \"I'd\": \"I would\",\n",
    "  \"I'd've\": \"I would have\",\n",
    "  \"I'll\": \"I will\",\n",
    "  \"I'll've\": \"I will have\",\n",
    "  \"I'm\": \"I am\",\n",
    "  \"I've\": \"I have\",\n",
    "  \"isn't\": \"is not\",\n",
    "  \"it'd\": \"it had\",\n",
    "  \"it'd've\": \"it would have\",\n",
    "  \"it'll\": \"it will\",\n",
    "  \"it'll've\": \"it will have\",\n",
    "  \"it's\": \"it is\",\n",
    "  \"let's\": \"let us\",\n",
    "  \"ma'am\": \"madam\",\n",
    "  \"mayn't\": \"may not\",\n",
    "  \"might've\": \"might have\",\n",
    "  \"mightn't\": \"might not\",\n",
    "  \"mightn't've\": \"might not have\",\n",
    "  \"must've\": \"must have\",\n",
    "  \"mustn't\": \"must not\",\n",
    "  \"mustn't've\": \"must not have\",\n",
    "  \"needn't\": \"need not\",\n",
    "  \"needn't've\": \"need not have\",\n",
    "  \"o'clock\": \"of the clock\",\n",
    "  \"oughtn't\": \"ought not\",\n",
    "  \"oughtn't've\": \"ought not have\",\n",
    "  \"shan't\": \"shall not\",\n",
    "  \"sha'n't\": \"shall not\",\n",
    "  \"shan't've\": \"shall not have\",\n",
    "  \"she'd\": \"she would\",\n",
    "  \"she'd've\": \"she would have\",\n",
    "  \"she'll\": \"she will\",\n",
    "  \"she'll've\": \"she will have\",\n",
    "  \"she's\": \"she is\",\n",
    "  \"should've\": \"should have\",\n",
    "  \"shouldn't\": \"should not\",\n",
    "  \"shouldn't've\": \"should not have\",\n",
    "  \"so've\": \"so have\",\n",
    "  \"so's\": \"so is\",\n",
    "  \"that'd\": \"that would\",\n",
    "  \"that'd've\": \"that would have\",\n",
    "  \"that's\": \"that is\",\n",
    "  \"there'd\": \"there had\",\n",
    "  \"there'd've\": \"there would have\",\n",
    "  \"there's\": \"there is\",\n",
    "  \"they'd\": \"they would\",\n",
    "  \"they'd've\": \"they would have\",\n",
    "  \"they'll\": \"they will\",\n",
    "  \"they'll've\": \"they will have\",\n",
    "  \"they're\": \"they are\",\n",
    "  \"they've\": \"they have\",\n",
    "  \"to've\": \"to have\",\n",
    "  \"wasn't\": \"was not\",\n",
    "  \"we'd\": \"we had\",\n",
    "  \"we'd've\": \"we would have\",\n",
    "  \"we'll\": \"we will\",\n",
    "  \"we'll've\": \"we will have\",\n",
    "  \"we're\": \"we are\",\n",
    "  \"we've\": \"we have\",\n",
    "  \"weren't\": \"were not\",\n",
    "  \"what'll\": \"what will\",\n",
    "  \"what'll've\": \"what will have\",\n",
    "  \"what're\": \"what are\",\n",
    "  \"what's\": \"what is\",\n",
    "  \"what've\": \"what have\",\n",
    "  \"when's\": \"when is\",\n",
    "  \"when've\": \"when have\",\n",
    "  \"where'd\": \"where did\",\n",
    "  \"where's\": \"where is\",\n",
    "  \"where've\": \"where have\",\n",
    "  \"who'll\": \"who will\",\n",
    "  \"who'll've\": \"who will have\",\n",
    "  \"who's\": \"who is\",\n",
    "  \"who've\": \"who have\",\n",
    "  \"why's\": \"why is\",\n",
    "  \"why've\": \"why have\",\n",
    "  \"will've\": \"will have\",\n",
    "  \"won't\": \"will not\",\n",
    "  \"won't've\": \"will not have\",\n",
    "  \"would've\": \"would have\",\n",
    "  \"wouldn't\": \"would not\",\n",
    "  \"wouldn't've\": \"would not have\",\n",
    "  \"y'all\": \"you all\",\n",
    "  \"y'alls\": \"you alls\",\n",
    "  \"y'all'd\": \"you all would\",\n",
    "  \"y'all'd've\": \"you all would have\",\n",
    "  \"y'all're\": \"you all are\",\n",
    "  \"y'all've\": \"you all have\",\n",
    "  \"you'd\": \"you had\",\n",
    "  \"you'd've\": \"you would have\",\n",
    "  \"you'll\": \"you you will\",\n",
    "  \"you'll've\": \"you you will have\",\n",
    "  \"you're\": \"you are\",\n",
    "  \"you've\": \"you have\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#main 단어만 추출 > 차후 이 단어들로 test\n",
    "def preprocessing_sentence(sentence, remove_stopwords = True):\n",
    "    #소문자화\n",
    "    sentence = sentence.lower()\n",
    "    # /n 제거\n",
    "    sentence = re.sub(r'/n',' ',sentence)\n",
    "    #괄호로 닫친 문자열 괄호 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)',' ',sentence)\n",
    "    #쌍따옴표 제거\n",
    "    sentence = re.sub('\"', ' ', sentence) \n",
    "    #약어 정규화\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")])\n",
    "    #소유격 제거\n",
    "    sentence = re.sub(r\"'s\\b\",\" \",sentence)\n",
    "    #특수문자 제거\n",
    "    sentence = re.sub(\"[^a-zA-Z]\",\" \", sentence)\n",
    "    \n",
    "    #불용어 제거\n",
    "    if my_stop_word_list:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in my_stop_word_list if len(word)>1)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word)>1)\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['facts'] = [preprocessing_sentence(i) for i in data['facts']]\n",
    "test['facts'] = [preprocessing_sentence(i) for i in test['facts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['facts'] = data['facts'].astype('str')\n",
    "test['facts'] = test['facts'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts_corpus_lose = ' '.join(data[data['first_party_winner'] == 0]['facts'])\n",
    "facts_corpus_win = ' '.join(data[data['first_party_winner'] == 1]['facts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "title_wordcloud = WordCloud(stopwords=STOPWORDS, background_color='white', height=2000, width=4000).generate(facts_corpus_lose)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(title_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "title_wordcloud = WordCloud(stopwords=STOPWORDS, background_color='white', height=2000, width=4000).generate(facts_corpus_win)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.imshow(title_wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "def get_vector(vectorizer, df, train_mode):\n",
    "    if train_mode:\n",
    "        X_facts = vectorizer.fit_transform(df['facts'])\n",
    "    else:\n",
    "        X_facts = vectorizer.transform(df['facts'])\n",
    "    X_party1 = vectorizer.transform(df['first_party'])\n",
    "    X_party2 = vectorizer.transform(df['second_party'])\n",
    "    \n",
    "    X = np.concatenate([X_party1.todense(), X_party2.todense(), X_facts.todense()], axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_vector(vectorizer, data, True)\n",
    "Y = data[\"first_party_winner\"]\n",
    "X_T = get_vector(vectorizer, test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.squeeze(np.asarray(X))\n",
    "X_T = np.squeeze(np.asarray(X_T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "X_T_scaled = scaler.transform(X_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm \n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_params = {\n",
    "                'verbose' : 0,\n",
    "                'random_state': 113,\n",
    "               # 'use_best_model' : True,\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# Classifiers\n",
    "names = [\n",
    "    \"Logistic Regression\",\n",
    "    \"KNN Classifier\",\n",
    "    \"Decision Tree\",\n",
    "    \"LinearSVC\",\n",
    "    \"Linear SVM\",\n",
    "    \"Poly SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"sigmoid SVM\",\n",
    "    \"Neural Network\",\n",
    "    \"Random Forest\",\n",
    "    \"SGD Classifier\",\n",
    "    \"Ridge Classifier\",\n",
    "    \"XGBoost\",\n",
    "    \"AdaBoost\",\n",
    "    \"Catboost\",\n",
    "    \"Gaussian Naive Bayes\"\n",
    "]\n",
    "\n",
    "models = [\n",
    "    LogisticRegression(max_iter = 1000),\n",
    "    KNeighborsClassifier(n_neighbors = 149, n_jobs = -1),\n",
    "    DecisionTreeClassifier(),\n",
    "    LinearSVC(random_state=113),\n",
    "    svm.SVC(kernel = 'linear'),\n",
    "    svm.SVC(kernel = 'poly'),\n",
    "    svm.SVC(kernel = 'rbf'),\n",
    "    svm.SVC(kernel = 'sigmoid'),\n",
    "    MLPClassifier(),\n",
    "    RandomForestClassifier(n_estimators = 100),\n",
    "    SGDClassifier(loss = 'hinge'),\n",
    "    RidgeClassifier(),\n",
    "    XGBClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    CatBoostClassifier(**cat_params),\n",
    "    GaussianNB()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Function to return summary of baseline models\n",
    "def score(X_train, y_train, X_val, y_val, names = names, models = models):\n",
    "    score_df, score_train, score_val = pd.DataFrame(), [], []\n",
    "    x = time.time()\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred, y_val_pred = model.predict(X_train), model.predict(X_val)\n",
    "        score_train.append(accuracy_score(y_train, y_train_pred))\n",
    "        score_val.append(accuracy_score(y_val, y_val_pred))\n",
    "    \n",
    "    score_df[\"Classifier\"], score_df[\"Training accuracy\"], score_df[\"Validation accuracy\"] = names, score_train, score_val\n",
    "    score_df.sort_values(by = 'Validation accuracy', ascending = False, inplace = True)\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chunbae/miniconda3/envs/rapids-23.04/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/home/chunbae/miniconda3/envs/rapids-23.04/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:237: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Validation accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.746738</td>\n",
       "      <td>0.592025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.552571</td>\n",
       "      <td>0.588957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.579755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.576687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sigmoid SVM</td>\n",
       "      <td>0.929394</td>\n",
       "      <td>0.567485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.561350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.561350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.558282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.558282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.546012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.999233</td>\n",
       "      <td>0.546012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Catboost</td>\n",
       "      <td>0.976976</td>\n",
       "      <td>0.539877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.999233</td>\n",
       "      <td>0.533742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Poly SVM</td>\n",
       "      <td>0.999233</td>\n",
       "      <td>0.475460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Classifier  Training accuracy  Validation accuracy\n",
       "13              AdaBoost           0.746738             0.592025\n",
       "1         KNN Classifier           0.552571             0.588957\n",
       "0    Logistic Regression           1.000000             0.579755\n",
       "8         Neural Network           1.000000             0.576687\n",
       "7            sigmoid SVM           0.929394             0.567485\n",
       "3              LinearSVC           1.000000             0.561350\n",
       "4             Linear SVM           1.000000             0.561350\n",
       "9          Random Forest           1.000000             0.558282\n",
       "11      Ridge Classifier           1.000000             0.558282\n",
       "6                RBF SVM           1.000000             0.555215\n",
       "10        SGD Classifier           1.000000             0.546012\n",
       "15  Gaussian Naive Bayes           0.999233             0.546012\n",
       "14              Catboost           0.976976             0.539877\n",
       "12               XGBoost           0.999233             0.533742\n",
       "2          Decision Tree           1.000000             0.521472\n",
       "5               Poly SVM           0.999233             0.475460"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(X_train, y_train, X_test, y_test, names = names, models = models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "GRID = [\n",
    "    {\n",
    "     'estimator': [MLPClassifier(random_state=113)],\n",
    "     'estimator__solver': ['adam'],\n",
    "     'estimator__learning_rate_init': [0.0001],\n",
    "     'estimator__max_iter': [300],\n",
    "     'estimator__hidden_layer_sizes': [(500, 400, 300, 200, 100), (400, 400, 400, 400, 400), (300, 300, 300, 300, 300), (200, 200, 200, 200, 200)],\n",
    "     'estimator__activation': ['logistic', 'tanh', 'relu'],\n",
    "     'estimator__alpha': [0.0001, 0.001, 0.005],\n",
    "     'estimator__early_stopping': [True, False]\n",
    "     }\n",
    "]\n",
    "\n",
    "PIPELINE = Pipeline([('estimator', MLPClassifier())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=PIPELINE, param_grid=GRID, \n",
    "                            scoring= \"accuracy\",\n",
    "                            n_jobs=-1, cv=5, refit=True, verbose=1, \n",
    "                            return_train_score=False)\n",
    "\n",
    "grid_search.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"최적의 파라미터 : {grid_search.best_params_}\")\n",
    "print(f\"최적의 파라미터로 모델의 정확도 : {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy score: 1.0\n",
      "Testing Accuracy score: 0.5797546012269938\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#classifiers = [('SGD Classifier', SGDClassifier(loss = 'hinge',random_state=113)),\n",
    "#               ('sigmoid SVM', svm.SVC(kernel = 'sigmoid', random_state=113)),\n",
    "#                ('Linear SVM', svm.SVC(kernel = 'linear', random_state=113))\n",
    "#              ]\n",
    "#vc = VotingClassifier(estimators=classifiers)\n",
    "clf = LogisticRegression(random_state=113)\n",
    "# Fit 'vc' to the traing set and predict test set labels\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_train=clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "print(\"Training Accuracy score:\",accuracy_score(y_train, y_pred_train))\n",
    "print(\"Testing Accuracy score:\",accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "k = 10 # a number of folds best is 20\n",
    "skfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=113)\n",
    "\n",
    "y_valid_pred = 0*Y\n",
    "y_test_pred = 0\n",
    "\n",
    "model = MLPClassifier(random_state=113)\n",
    "\n",
    "for i, (train_index, test_index) in tqdm(enumerate(skfold.split(X, Y))):    \n",
    "    X_train_fold, X_valid_fold = X[train_index], X[test_index]\n",
    "    y_train_fold, y_valid_fold = Y.iloc[train_index], Y.iloc[test_index]\n",
    "    \n",
    "    print( \"\\nFold \", i)\n",
    "    \n",
    "    fit_model = model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "\n",
    "    def score_model(model,X_train, X_test, y_train, y_test,\n",
    "               show_plot=True):   \n",
    "        y_pred = model.predict(X_test)\n",
    "        print(f\"accuracy_score : {accuracy_score(y_test, y_pred)}\")\n",
    "    \n",
    "        predictions_comparision = pd.DataFrame({'Actual': y_test.tolist(), 'Predicted': y_pred.tolist()}).sample(25)\n",
    "        if show_plot == True:\n",
    "            predictions_comparision.plot(kind=\"bar\", figsize=(12,8),title=\"Actual vs predicted values\")\n",
    "            print(predictions_comparision.sample(10))    \n",
    "    \n",
    "        return {\n",
    "            \"accuracy_score\" : accuracy_score(y_test, y_pred)\n",
    "            }\n",
    "    score_model(fit_model, X_train_fold, X_valid_fold, y_train_fold, y_valid_fold, show_plot=True)\n",
    "    \n",
    "    # Predict value Clipping\n",
    "    y_test_pred += fit_model.predict_proba(X_T)\n",
    "    \n",
    "y_test_pred /= k  # Average test set predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_test_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>TEST_1235</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>TEST_1236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>TEST_1237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>TEST_1238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>TEST_1239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  first_party_winner\n",
       "0     TEST_0000                   0\n",
       "1     TEST_0001                   0\n",
       "2     TEST_0002                   1\n",
       "3     TEST_0003                   0\n",
       "4     TEST_0004                   1\n",
       "...         ...                 ...\n",
       "1235  TEST_1235                   0\n",
       "1236  TEST_1236                   0\n",
       "1237  TEST_1237                   0\n",
       "1238  TEST_1238                   0\n",
       "1239  TEST_1239                   1\n",
       "\n",
       "[1240 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub['first_party_winner'] = clf.predict(X_T)\n",
    "#sub['first_party_winner'] = np.argmax(y_test_pred, axis = 1)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    674\n",
       "0    566\n",
       "Name: first_party_winner, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['first_party_winner'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submit_230630(1)_RL.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
